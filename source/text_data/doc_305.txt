14.3 Term Clustering
285
a pairwise score between two words w1 and w2. If these scores are normalized, we
can still cluster the entire set of terms by using the pairwise scores.
As in all clustering problems, definition of similarity is important. In the case of
term clustering, the question is how we should define the similarity between two
terms. It is easy to see that the paradigmatic relations and syntagmatic relations
between words (or terms) are both natural candidates for serving as a basis to
define similarity. The paradigmatic relation similarity would lead to clusters of
terms that tend to occur in very similar contexts with the same relative “location”
in the context, whereas the syntagmatic relations would lead to clusters of terms
that are semantically related and also tend to co-occur in similar contexts but in
different “locations.”
In the rest, we will first revisit a method for finding semantically related words
from earlier in this book. Then, we introduce the concept of pointwise mutual
information and show how it can also be used to find related terms. We end with
an introduction to more advanced term clustering methods.
14.3.1
Semantically Related Terms
Recall from Section 3.4 where we found which words were semantically related with
the term computer. Figure 14.5 is reproduced here from Section 3.4.
the 0.03
a 0.02
is 0.015
we 0.01
. . .
computer 0.00001
. . .
the 0.032
a 0.019
is 0.014
we 0.008
computer 0.004
software 0.0001
. . .
text 0.00006
computer 400
software 150
program 104
. . .
text 3.0
. . .
the 1.1
a 0.99
is 0.9
we 0.8
Background LM: p(w|B)
General
background
English text
B
Topic LM: p(w|“computer”)
Normalized topic LM:
p(w|“computer”)/p(w|B)
All documents
containing word
“computer”
Figure 14.5
Using topic language models and a background language model to find semantically
related words.
