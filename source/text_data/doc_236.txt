216
Chapter 10
Web Search
knowledge will be used to help a user improve productivity in finishing a task.
In this dimension, we anticipate that future intelligent information systems will
provide interactive task support.
We should emphasize interactive here, because it’s important to optimize the
combined intelligence of users and the system. We can get some help from users
in a natural way without assuming the system has to do everything. That is, the user
and the machine can collaborate in an intelligent and efficient way. This combined
intelligence will be high and in general, we can minimize the user’s overall effort
in solving their current problem.
This is the big picture of future intelligent information systems, and this hope-
fully can provide us with some insights about how to make further innovations on
top of what we have today and also motivate the additional techniques to be covered
in the later chapters of the book.
Bibliographic Notes and Further Reading
The classic reference for PageRank is Page et al. [1999], and that for HITS is
Kleinberg [1999]. Lin and Dyer [2010] provides an excellent introduction to us-
ing MapReduce for text processing applications, including particularly a detailed
treatment of how to use MapReduce for constructing an inverted index. Liu [2009]
gives an excellent survey of research work on learning to rank.
Exercises
10.1. Examine the robots.txt file for several common sites. Can you figure out
the format of this file? What type of data do these sites not want you to crawl? What
is a user agent?
10.2. Simple Web Crawlers.
On Linux or Mac, try using wget to download a
web page:
wget http://www.[insert-domain-here].com/
The file is probably saved with the extension .html. Open it up in your favorite
text editor. It’s just a bunch of HTML! This is the same thing you’d see if you right
click the page in a browser and select “View Source”.
10.3. Parsing Web Content.
An important step of web crawling is parsing the
HTML into plaintext. There are many libraries available that do this. These libraries
can also provide all the outgoing links (the a href= . . . tags). It’s the crawler’s job
