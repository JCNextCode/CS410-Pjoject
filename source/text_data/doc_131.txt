6.4 Probabilistic Retrieval Models
111
to a query q, or p(R = 1 | d, q) where R ∈ {0, 1} is a binary random variable denoting
relevance. In other words, we introduce a binary random variable R and we model
the query and the documents as observations from random variables.
Note that in the vector space model, we assume that documents are all equal-
lengthvectors.Here, weassumedtheyarethedataobservedfromrandomvariables.
Thus, the problem is to estimate the probability of relevance.
In this category of models, there are many different variants. The classic prob-
abilistic model has led to the BM25 retrieval function, which we discussed in the
vector space model section because its form is quite similar to these types of mod-
els. We will discuss another special case of probabilistic retrieval functions called
language modeling approaches to retrieval. In particular, we’re going to discuss
the query likelihood retrieval model, which is one of the most effective models in
probabilistic models. There is also another line of functions called divergence-from-
randomness models (such as the PL2 function [Amati and Van Rijsbergen 2002]). It’s
also one of the most effective state-of-the-art retrieval models.
In query likelihood, our assumption is that this probability of relevance can
be approximated by the probability of a query given a document and relevance,
p(q | d, R = 1). Intuitively, this probability just captures the following probability:
if a user likes document d, how likely would the user enter query q in order to
retrieve document d? The condition part contains document d and R = 1, which
can be interpreted as the condition that the user likes document d. To understand
this idea, let’s first take a look at the basic idea of probabilistic retrieval models.
Figure 6.19 lists some imagined relevance status values (or relevance judgments)
of queries and documents. It shows that q1 is a query that the user typed in and d1 is
a document the user has seen. A “1” in the far right column means the user thinks
d1 is relevant to q1. The R here can be also approximated by the clickthrough data
that the search engine can collect by watching how users interact with the search
results. In this case, let’s say the user clicked on document d1, so there’s a one
associated with the pair (q1, d1). Similarly, the user clicked on d2, so there’s a one
associated with (q1, d2). Thus, d2 is assumed to be relevant to q1 while d3 is non-
relevant, d4 is non-relevant, d5 is again relevant, and so on and so forth. Perhaps
the second half of the table (after the ellipses) is from a different user issuing the
same queries. This other user typed in q1 and then found that d1 is actually not
useful, which is in contrast to the first user’s judgement.
We can imagine that we have a large amount of search data and are able to ask
the question, “how can we estimate the probability of relevance?” Simply, if we look
at all the entries where we see a particular d and a particular q, we can calculate
how likely we will see a one in the third column. We can first count how many times
