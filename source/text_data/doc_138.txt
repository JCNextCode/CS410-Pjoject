118
Chapter 6
Retrieval Models
In practice, we score the document for this query by using a logarithm of the
query likelihood:
score(q, d) = log p(q | d) =
n
�
i=1
log p(wi | d) =
�
w∈V
c(w, q) log p(w | d). (6.5)
We do this to avoid having numerous small probabilities multiplied together,
which could cause underflow and precision loss. By transforming using a loga-
rithm, we maintain the order of these documents while simultaneously avoiding
the underflow problem. Note the last term in the equation above; in this sum, we
have a sum over all the possible words in the vocabulary V and iterate through
each word in the query. Essentially, we are only considering the words in the query
because if a word is not in the query, its contribution to the sum would be zero.
The only part we don’t know is this document language model, p(w | d). There-
fore, we can convert the retrieval problem into the problem of estimating this
document language model so that we can compute the probability of a query being
generated by each document. Different estimation methods for p(w | d) lead to dif-
ferent ranking functions, and this is just like the different ways to place a document
into a vector in the vector space model. Here, there are different ways to estimate
parameters in the language model, which lead to different ranking functions for
query likelihood.
6.4.2
Smoothing the Document Language Model
When calculating the query likelihood retrieval score, recall that we take a sum of
log probabilities over all of the query words, using the probability of a word in the
query given the document (i.e., the document language model). The main task now
is to estimate this document language model. In this section we look into this task
in more detail.
First of all, how do we estimate this language model? The obvious choice would
be the maximum likelihood estimation (MLE) that we have seen before in Chap-
ter 2. In MLE, we normalize the word frequencies in the document by the document
length. Thus, all the words that have the same frequency count will have an equal
probability under this estimation method. Note that words that have not occurred
in the document will have zero probability. In other words, we assume the user will
sample a word from the document to formulate the query, and there is no chance
of sampling any word that is not in the document. But we know that’s not good,
so how would we improve this? In order to assign a non-zero probability to words
that have not been observed in the document, we would have to take away some
