324
Chapter 16
Text Summarization
and the actions they perform. Once these actors and roles are discovered, they are
stored in some internal representation. To generate the actual text, some represen-
tations are chosen from the parsed collection, and English sentences are created
based on them; this is called realization.
Such realization systems have much more fine-grained control over the gener-
ated text than the basic abstractive language model generator described above. A
templated document structure may exist (such as intro→paragraph 1→paragraph
2→conclusion), and the structures are chosen to fill each spot. This control over
text summarization and layout enables an easily-readable summary since it has a
natural topical flow. In this environment, it would be possible to merge similar sen-
tences with conjunctions such as and or but, depending on the context. To make
the summary sound even more natural, pronouns can be used instead of entity
names if the entity name has already been mentioned. Below are examples of these
two operations:
Gold prices fell today. Silver prices fell today. → Gold and silver prices fell today.
Company A lost 9.43% today. Company A was the biggest mover. → Company A lost
9.43% today. It was the biggest mover.
Even better would be
Company A was today’s biggest mover, losing 9.43%.
These operations are possible since the entities are stored in a structured format.
For more on advanced natural language generation, we suggest Reiter and Dale
[2000], which has a focus on practicality and implementation.
16.4
Evaluation of Text Summarization
In extractive summarization, representative sentences were selected from passages
in the text and output as a summary. This solution is modeled as an information
retrieval problem, and we can evaluate it as such. Redundancy is a critical issue,
and the MMR technique we discussed attempts to alleviate it. When doing our
evaluation, we should consider redundant sentences to be irrelevant, since the user
does not want to read the same information twice. For a more detailed explanation
of IR evaluation measures, please consult Chapter 9.
For full output scoring, we should prefer IR evaluation metrics that do not
take into account result position. Although our summary is generated by ranked
sentences per passage, the entire output is not a ranked list since the original
documentiscomposedofmultiplepassages.Thereforewecanuseprecision, recall,
and F1 score.
