B
APPENDIX
Expectation-
Maximization
The Expectation-Maximization (EM) algorithm is a general algorithm for maxi-
mum-likelihood estimation where the data are “incomplete” or the likelihood
function involves latent variables. Note that the notion of “incomplete data” and
“latent variables” are related: when we have a latent variable, we may regard our
data as being incomplete since we do not observe values of the latent variables;
similarly, when our data are incomplete, we often can also associate some latent
variable with the missing data. For language modeling, the EM algorithm is often
used to estimate parameters of a mixture model, in which the exact component
model from which a data point is generated is hidden from us.
Informally, the EM algorithm starts with randomly assigning values to all the pa-
rameters to be estimated. It then iteratively alternates between two steps, called the
expectation step (i.e., the “E-step”) and the maximization step (i.e., the “M-step”),
respectively. In the E-step, it computes the expected likelihood for the complete
data (the so-called Q-function) where the expectation is taken with respect to the
computed conditional distribution of the latent variables (i.e., the “hidden vari-
ables”) given the current settings of parameters and our observed (incomplete)
data.IntheM-step, itre-estimatesalltheparametersbymaximizingtheQ-function.
Once we have a new generation of parameter values, we can repeat the E-step and
another M-step. This process continues until the likelihood converges, reaching
a local maxima. Intuitively, what EM does is to iteratively augment the data by
“guessing” the values of the hidden variables and to re-estimate the parameters
by assuming that the guessed values are the true values.
The EM algorithm is a hill-climbing approach, thus it can only be guaranteed to
reach a local maxima. When there are multiple maximas, whether we will actually
reach the global maxima depends on where we start; if we start at the “right hill,”
we will be able to find a global maxima. When there are multiple local maximas,
it is often hard to identify the “right hill.” There are two commonly used strategies
