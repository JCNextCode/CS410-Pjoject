374
Chapter 17
Topic Analysis
Probability that w in doc d is generated from topic θj
Probability that w in doc d is generated from background θB
Use of Bayes Rule
Hidden variable (= topic indicator): zd,w 2 {B, 1, 2, …, k}
p(zd,w = j) = 
p(zd,w = B) = 
∑k
j=1π
(n) p(n)(w|θj)
d,j
λBp(w|θB)
λBp(w|θB) + (1 – λB)
EM Algorithm for PLSA: E-Step
∑k
j′=1π
(n) p(n)(w|θj′)
d,j′
π
(n) p(n)(w|θj)
d,j
Figure 17.32
E-Step of the EM Algorithm for estimating PLSA.
from topic θj, but rather this probability conditioned on having not chosen the
background model. In other words, the probability of generating a word using θj
is (1 − p(zd,w = B))p(zd,w = j). In the case of having just one topic other than the
background model, we would have p(zd,w = j) = 1 only for θj.
Note that we use document d here to index the word w. In our model, whether
w has been generated from a particular topic actually depends on the document!
Indeed, the parameter πd,j is tied to each document, and thus each document
can have a potentially different topic coverage distribution. Such an assumption is
reasonable as different documents generally have a different emphasis on specific
topics. This means that in the E-step, the inferred probability of topics for the
same word can be potentially very different for different documents since different
documents generally have different πd,j values.
The M-step is also similar to that in the simple mixture model. We show the
equations in Figure 17.33. We see that a key component in the two equations, for
re-estimating π and p(w | θ) respectively, is c(w, d)(1 − p(zd,w = B))p(zd,w = j),
which can be interpreted as the allocated counts of w to topic θj. Intuitively, we use
the inferred distribution of z values from the E-step to split the counts of w among
all the distributions. The amount of split counts of w that θj can get is determined
based on the inferred likelihood that w is generated by topic θj.
Once we have such a split count of each word for each distribution, we can easily
pool together these split counts to re-estimate both π and p(w | θ), as shown in
Figure 17.33. To re-estimate πd,j, the probability that document d covers topic θj,
