152
Chapter 8
Search Engine Implementation
Doc ID: 90, count: 4, position 90, position 93, position...
Doc ID: 141, count: 1, position 100
Doc ID: 144, count: 2, position 34, position 89
...
which is the counts and position information for the 78 documents that term ID 56
appears in. Notice how the doc IDs (and positions) are stored in increasing order;
this is a fact we will take advantage of when compressing the postings file. Also
make note of the large difference in size of the lexicon and postings file. For each
entry in the lexicon, we know we will only store three values per term. In the postings
file, we store at least three values (doc ID, count, positions) for each document that
the term appears in. If the term appears in all documents, we’d have a list of the
length of the number of documents in the corpus. This is true for all unique terms.
For this reason, we often assume that the lexicon can fit into main memory and the
postings file resides on disk, and is seeked into based on pointers from the lexicon.
Indexing is the process of creating these data structures based on a set of tok-
enized documents. A popular approach for indexing is the following sorting-based
approach.
.
Scan the raw document stream sequentially. In tokenization, assign each
document an ID. Tokenize each document to obtain term IDs, creating new
term IDs as needed.
.
While scanning documents, collect term counts for each term-document pair
and build an inverted index for a subset of documents in memory. When we
reach the limit of memory, write the incomplete inverted index into the disk.
(It will be the same format as the resulting postings file, just smaller.)
.
Continue this process to generate many incomplete inverted indices (called
“runs”) all written on disk.
.
Merge all these runs in a pair-wise manner to produce a single sorted (by
term ID) postings file. This algorithm is essentially the merge function from
mergesort.
.
Once the postings file is created, create the lexicon by scanning through the
postings file and assigning the offset values for each term ID.
Figure8.2showshowdocumentsproducetermsoriginallyindocumentIDorder.
The terms from multiple documents are then sorted by term ID in small postings
chunks that fit in memory before they are flushed to the disk.
