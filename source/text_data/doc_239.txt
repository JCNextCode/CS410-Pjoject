Exercises
219
html = File.open(’filename.html’).read
noko = Nokogiri::HTML(html)
puts noko.text # or save to another file
For this method, you will have to install the Nokogiri library.
Experiment with one or both of these cleaners to parse your crawled files. Or,
write your own cleaner with different technology!
10.7. Create a dynamically updating web search engine by combining your crawler,
cleaner, and META. You can schedule the crawler to run during a specified time
interval. Once new files are downloaded and cleaned, recreate the index.
10.8. Give a suggestion on how to improve a ranking function for web search to
take in additional page information such as the title field or page layout.
10.9. Write MapReduce pseudocode that creates an inverted index that contains
all the necessary information to rank documents using Dirichlet prior smoothing
or Jelinek-Mercer smoothing.
10.10. If we add a new page to the web, what happens to other existing PageRank
scores? Explain.
10.11. Compare PageRank with Personalized PageRank. Can one or both be pre-
computed to save query processing time? Why or why not?
10.12. Give a query where a high-scoring authority page could be a desired docu-
ment and a query where a high-scoring hub page could be a desired document.
10.13. After reading Chapter 15, you may have some alternative ideas of how to
design a learning to rank algorithm. For example, can you outline an idea of how
we can optimize (e.g.) MAP for a set of training queries?
10.14. Thinking back to Chapter 9, what is a good objective function to optimize
for learning to rank? Is MAP the best choice? Why or why not?
10.15. Outline a method for combining user feedback with a learning to rank
approach.
