6.4 Probabilistic Retrieval Models
127
discounted the numerator will be. Finally, we can see the |d| in the denominator is a
form of document length normalization, since as |d| grows, the overall term weight
would decrease, suggesting that the impact of αd in this case is clearly to penalize
a long document. The second fraction can also be considered as the ratio of two
probabilities; if the ratio is greater than one, it means the probability of w in d is
greater than appearing by chance in the background. If the ratio is less than one,
the chance of seeing w in d is actually less likely than observing it in the collection.
What’s also important to note is that we received this weighting function auto-
matically by making various assumptions, whereas in the vector space model, we
had to go through those heuristic design choices in order to get this. These are the
advantages of using this kind of probabilistic reasoning where we have made ex-
plicit assumptions. We know precisely why we have a logarithm here, and precisely
why we have these probabilities. We have a formula that makes sense and does
TF-IDF weighting and document length normalization.
Let’s look at the complete function for Dirichlet prior smoothing now. We know
what pseen is and we know that αd =
μ
|d|+μ:
pseen(w | d) = c(w, d) + μ . p(w | C)
| d | +μ
=
|d|
|d| + μ
. c(w, d)
|d|
+
μ
|d| + μ
. p(w | C), (6.11)
therefore,
pseen(w | d)
αd . p(w | C) =
c(w,d)+μ.p(w|C)
|d|+μ
μ.p(w|C)
|d|+μ
= 1 +
c(w, d)
μ . p(w | C).
(6.12)
We can now substitute this into the complete formula:
scoreDIR(q, d) =
�
w∈q,d
c(w, q) log
�
1 +
c(w, d)
μ . p(w | C)
�
+ |q| log
μ
μ + |d|.
(6.13)
The form of the function looks very similar to the Jelinek-Mercer scoring func-
tion. We compute a ratio that is sublinearly scaled by a non-negative logarithm.
Both TF and IDF are computed in almost the exact same way. The difference here
is that Dirichlet prior smoothing can capture document length normalization dif-
ferently than Jelinek-Mercer smoothing. Here, we have retained the |q| log αd term
since αd depends on the document, namely |d|. If |d| is large, then less extra mass
is added onto the final score; if |d| is small, more extra mass is added to the score,
effectively rewarding a short document.
To summarize this section, we’ve talked about two smoothing methods: Jelinek-
Mercer, whichisdoingthefixedcoefficientlinearinterpolation, andDirichletprior,
