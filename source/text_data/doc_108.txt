88
Chapter 6
Retrieval Models
derived from the classific probabilistic retrieval framework is BM25 [Robertson and
Zaragoza 2009], but since the retrieval function of BM25 is so similar to a vector
space retrieval model, we have chosen to cover it as a variant of the vector space
model.
The third kind of model is probabilistic inference [Turtle and Croft 1990]. Here
the idea is to associate uncertainty to inference rules. We can then quantify the
probability that we can show that the query follows from the document. This family
of models is theoretically appealing, but in practice, they are often reduced to
models essentially similar to vector-space model or a regular probabilistic retrieval
model.
Finally, there is also a family of models that use axiomatic thinking [Fang et al.
2011].Theideaistodefineasetofconstraintsthatwehopeagoodretrievalfunction
satisfies. In this case the problem is to find a good ranking function that can satisfy
all the desired constraints. Interestingly, although all these models are based on
different thinking, in the end the retrieval functions tend to be very similar and
involve similar variables. The axiomatic retrieval framework has proven effective
for diagnosing deficiencies of a retrieval model and developing improved retrieval
models accordingly (e.g., BM25+ [Lv and Zhai 2011]).
Although many models have been proposed, very few have survived extensive ex-
perimentation to prove effective and robustness. In this book, we have chosen to
cover four specific models (i.e., BM25, pivoted length normalization, query likeli-
hood with JM smoothing, and query likelihood with Dirichlet prior smoothing) that
are among the very few most effective and robust models.1
6.2
Common Form of a Retrieval Function
Before we introduce specific models, we first take a look at the common form of
a state-of-the-art retrieval model and examine some of the common ideas used
in all these models. This is illustrated in Figure 6.1. First, these models are all
based on the assumption of using a bag-of-words representation of text. This was
explained in detail in the natural language processing chapter. A bag-of-words
representation remains the main representation used in all the search engines.
With this assumption, the score of a query like presidential campaign news, with
respect to a document d, would be based on scores computed on each individual
query word. That means the score would depend on the score of each word, such
as presidential, campaign, and news.
1. PL2 is another very effective model that the readers should also know of [Amati and Van Rijs-
bergen 2002].
