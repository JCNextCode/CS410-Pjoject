6.2 Common Form of a Retrieval Function
89
f (q = “presidential campaign news”,   d  )
g(“campaign”,   d  )
g(“news”,   d  )
g(“presidential”,   d  )
“Bag of Words”
How many times does “presidential” occur in d?
          Term frequency (TF):   c(“presidential”, d)
How long is d?          Document length:   |d|
How often do we see “presidential” in the entire collection?
          Document frequency:   DF(“presidential”)
          P(“presidential”|collection)
Figure 6.1
Illustration of common ideas for scoring with a bag-of-words representation.
We can see there are three different components, each corresponding to how
well the document matches each of the query words. Inside of these functions, we
see a number of heuristics. For example, one factor that affects the function g is how
many times the word presidential occurs in each document. This is called a term
frequency (TF). We might also denote this as c(presidential, d). In general, if the
word occurs more frequently in the document, the value of this function would be
larger. Another factor is the document length. In general, if a term occurs in a long
document many times, it is not as significant as if it occurred the same number of
times in a short document (since any term is expected to occur more frequently
in a long document). Finally, there is a factor called document frequency. This
looks at how often presidential occurs at least once in any document in the entire
collection. We call this the document frequency, or DF, of presidential. DF attempts
to characterize the popularity of the term in the collection. In general, matching a
rare term in the collection is contributing more to the overall score than matching a
common term. TF, DF, and document length capture some of the main ideas used
in pretty much all state-of-the-art retrieval models. In some other models we might
also use a probability to characterize this information.
A natural question is: Which model works the best? It turns out that many
models work equally well, so here we list the four major models that are generally
regarded as state-of-the-art:
.
pivoted length normalization [Singhal et al. 1996];
.
Okapi BM25 [Robertson and Zaragoza 2009];
