224
Chapter 11
Recommender Systems
input, perhaps from the user’s specified keywords or chosen categories. This is fed
into the system as the initial user profile.
Next, there is a utility function to help the system make decisions; it helps the
system decide where to set an acceptance threshold θ determining whether or
not the current item should be shown to the user. The learning module adjusts
its parameters based on the user’s feedback over time. Typically in information
filtering applications, the users’ information need is stable. Due to this, the system
wouldhavemanyopportunitiestoobservetheuseriftheuserviewsarecommended
item, since the user can indicate whether the recommended item was relevant or
not. Thus, such feedback can be long-term, allowing the system to collect much
information about this user’s interests, which is then used to improve the classifier.
How do we know this filtering system actually performs well? In this case, we
cannot use the ranking evaluation measures such as MAP or NDCG because we
can’t afford waiting for a significant number of documents to rank them to make a
decision for the user; the system must make a decision in real time. In general, this
decision is whether the item is above the acceptance threshold θ or not. In other
words, we’re trying to decide absolute relevance. One common strategy is to use a
utility function, and below is an example of a linear utility function:
U = 3 . |R| − 2 . |R′|,
(11.1)
where R is the set of relevant documents delivered to the user and R′ is the set
of non-relevant documents delivered to the user (that the user rejected). In a way,
we can treat this as a gambling game. If the system delivers one good item, let’s
say you win $3, or you gain $3. If you deliver a bad document, you would lose $2.
This utility function measures how much money you would accumulate (or lose)
by considering this kind of game. It’s clear that if you want to maximize this utility
function, your strategy should be to deliver as many good items as possible while
simultaneously minimizing the delivery of bad items.
One interesting question here is how to set these coefficients. We just showed
a 3 and a −2 as the possible coefficients, but we can ask the question “are they
reasonable?” What about other choices? We could have 10 and −1, or 1 and −10.
How would these utility functions affect the system’s output? If we use 10 and −1,
you will see that while we get a big reward for delivering a good document, we
incur only a small penalty for delivering a bad one. Intuitively, the system would
be encouraged to deliver more documents, since delivering more documents gives
a better chance of obtaining a high reward. If we choose 1and −10, it is the opposite
case: we don’t really get such a big prize if a good document is delivered, while a
