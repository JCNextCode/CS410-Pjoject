A.5 Bayesian Estimate of Multinomial Parameters
463
largely unrepresented, just like the words the, to, of , and from are common while
many words such as preternatural are rare.
A.5
Bayesian Estimate of Multinomial Parameters
Let’s do parameter estimation with our multinomial distribution and relate it to
the Beta-binomial model from before. For MLE, we would have
θi = xi
n .
(A.14)
Using Bayes’ rule, we represent the posterior as the product of the likelihood
(multinomial) and prior (Dirichlet):
p(θ | D, α) ∝ p(D | θ)p(θ | α)
∝
k�
i=1
θxi
i
k�
i=1
θαi−1
i
=
k�
i=1
θxi+αi−1
i
.
We say these are proportional because we left out the constant of proportionality
in the multinomial and Dirichlet distributions (the ratio with Gammas). We can
now observe that the posterior is also a Dirichlet as expected due to the conjugacy.
To actually obtain the Bayesian estimate, we’d need to fully substitute the multi-
nomial and Dirichlet distributions into the posterior and integrate over all θs to
get our estimate. Since this isn’t a note on calculus, we simply display the final
answer as
E[θi | D] =
xi + αi
n + �k
j=1 αj
.
(A.15)
This looks very similar to the binomial estimation! We see the Dirichlet hyper-
parameters act as pseudo counts, smoothing our estimate.
In Dirichlet prior smoothing for information retrieval, we have the formula:
p(w | d) = c(w, d) + μp(w | C)
|d| + μ
.
(A.16)
So we have x = c(w, d) and n = |d|, the count of the current word in a document
and the length of the document respectively. Then we have αi = μp(w | C) and
μ = �k
j=1 αj, the number of pseudo counts for word w and the total number of
pseudo counts. Can you tell what the vector of hyperparameters for query likelihood
