194
Chapter 10
Web Search
that gets updated very frequently, you may need to re-crawl even multiple times on
the same day. The second factor to consider is how frequently a particular page is
accessed by users of the search engine system. If it’s a high-utility page, it’s more
important to ensure it is fresh. Compare it with another page that has never been
fetched by any users for a year; even though that unpopular page has been changed
a lot, it’s probably not necessary to crawl that page—or at least it’s not as urgent—to
maintain its freshness.
10.2
Web Indexing
In this section, we will discuss how to create a web-scale index. After our crawler
deliversgigabytesorterabytesofdata, thenextstepistousetheindexertocreatethe
invertedindex.Ingeneral, wecanusethestandardinformationretrievaltechniques
for creating the index, but there are new challenges that we have to solve for web
scale indexing. The two main challenges are scalability and efficiency.
The index will be so large that it cannot actually fit into any single machine
or single disk, so we have to store the data on multiple machines. Also, because
the data is so large, it’s beneficial to process the data in parallel so that we can
produce the index quickly. To address these challenges, Google has made a number
of innovations. One is the Google File System, which is a general distributed file
system that can help programmers manage files stored on a cluster of machines.
The second is MapReduce, which is a general software framework for supporting
parallel computation. Hadoop is the most well known open source implementation
of MapReduce, now used in many applications.
Figure 10.1 shows the architecture of the Google File System (GFS). It uses a very
simple centralized management mechanism to manage all the specific locations of
files. That is, it maintains a file namespace and lookup table to know where exactly
each file is actually stored. The application client talks to the GFS master node,
which obtains specific locations of the files to process. This filesystem stores its
files on machines in fixed-size chunks; each data file is separated into many 64 MB
chunks. These chunks are replicated to ensure reliability. All of these details are
something that the programmer doesn’t have to worry about, and it’s all taken care
of by this filesystem. From the application perspective, the programmer would see
a normal file. The program doesn’t have to know where exactly it’s stored, and can
just invoke high level operators to process the file. Another feature is that the data
transfer is directly between application and chunk servers, so it’s efficient in this
sense as well.
On top of the GFS, Google proposed MapReduce as a general framework for par-
allel programming. This supports tasks like building an inverted index. Like GFS,
