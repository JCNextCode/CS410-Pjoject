436
Chapter 19
Joint Analysis of Text and Structured Data
Causality
test
Ideal causal
topics
Pure topic model
Topic coherence
Topic-time series causality
Figure 19.16
Alternating optimization of coherence and causality/correlation. (Courtesy of Hyun
Duk Kim)
The whole process is seen as a heuristic way of optimizing causality and coher-
ence, which is precisely our goal in discovery of causal topics. When applying the
topic model, we ensure the semantic coherence in the discovered topics, but when
splitting a topic into positively and negatively subtopics, we improve the correlation
with the time series, essentially iteratively improving both coherence and correla-
tion (causality), as illustrated in Figure 19.16.
Here we see that the pure topic models will be very good at maximizing topic
coherence, thus scoring high on the x-axis, meaning the discovered topics will all
be meaningful. If we only use a causality test or correlation measure, then we would
generate a set of words that are strongly correlated with the time series, thus scor-
ing high on the y-axis (causality), but they aren’t necessarily coherent semantically.
Our goal is to have a causal topic that scores high, in both topic coherence and
correlation. The approach discussed above can be regarded as an alternate way to
maximize both axes. When we apply the topic models we’re maximizing the co-
herence, while when we decompose the topic model words into sets of words that
are very strongly correlated with the time series, we would select the most strongly
correlated words with the time series. Thus we are, in effect, pushing the model
back to the causal dimension to make it better in causal scoring. When we apply
the selected words as a prior to guide topic models in topic discovery, we again go
back to optimize the coherence. Eventually, such an iterative process can be ex-
pected to reach a compromise of semantic coherence and strong correlation with
time series.
