402
Chapter 18
Opinion Mining and Sentiment Analysis
★★★★★
Term
weights
0.0
3.9
0.1
–0.2
0.1
1.7
0.1
3.9
2.1
1.2
1.7
1.2
0.6
Aspect segments
location: 1
amazing: 1
walk: 1
far: 1
room: 1
nicely: 1
appointed: 1
comfortable: 1
nice: 1
accommodating: 1
smile: 1
friendliness: 1
attentiveness: 1
“A friend and I stayed at the Hotel …
The hotel was very nice. The location
was amazing. We could walk almost
anywhere, but … far. The room was
very nicely appointed and the bed
was sooo comfortable. Even though
the bathroom door did not close
all the way, it was still very private.…
But what I liked best about the hotel
was the staff. They were soooo nice
and accommodating …”
3.8
4.8
5.8
0.2
0.2
0.6
Aspect
rating
Aspect
weight
αi(d)
βi,w
ri(d)
Latent!
Observed
Latent rating regression
Aspect segmentation
+
rd
ci(w, d)
Figure 18.10
A two-step approach to solving the LARA problem. (Courtesy of Hongning Wang)
As input, we are given a review with the overall rating. First, we will segment
the aspects; we’re going to pick out what words are talking about location, what
words are talking about room condition, and so on. In particular, we will obtain the
counts of all the words in each segment, denoted by ci(w, d), where i is a particular
segment index. This can be done by using seed words like location, room, or price
to retrieve the aspect label of each segment. From those segments, we can further
mine correlated words with these seed words, which allows us to segment the text
into partitions discussing different aspects. Later, we will see that we can also use
unsupervised models to do the segmentation.
In the second stage, Latent Rating Regression, we’re going to use these words
and their frequencies in different aspects to predict the overall rating. This pre-
diction happens in two stages. In the first stage, we’re going to use the weights of
these words in each aspect to predict the aspect rating. For example, if in the dis-
cussion of location, you see a word like amazing mentioned many times, it will have
a high weight (in the figure it’s given a weight of 3.9). This high weight increases the
aspect rating for location. In the case of another word like far, which is mentioned
many times, the weight will decrease. The aspect ratings assume that it will be a
weighted combination of these word frequencies where the weights are the senti-
