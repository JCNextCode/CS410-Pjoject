108
Chapter 6
Retrieval Models
Pivoted length normalization VSM
f (q, d) =
�
w∈q∩d
c(w, q)ln(1 + ln(1 + c(w, d)))
1 − b + b |d|
avdl
log M + 1
df(w)
b ∈ [0, 1]
BM25/Okapi
f (q, d) =
�
w∈q∩d
c(w, q)
(k + 1)c(w, d)
c(w, d) + k(1 − b + b |d|
avdl )
log M + 1
df(w)
b ∈ [0, 1], k ∈ [0, +∞)
Figure 6.18
State-of-the-art vector space models: pivoted length normalization and Okapi BM25.
vector space model ranking functions that we have already examined, we will end
up with state-of-the-art retrieval models, some of which are shown in Figure 6.18.
Let’s take a look at each of them. The first one is called pivoted length normaliza-
tion. We see that it’s basically the TF-IDF weighting model that we have discussed.
The IDF component appears in the last term. There is also a query TF component,
and in the middle there is normalized TF. For this, we have the double logarithm
as we discussed before; this is to achieve a sublinear transformation. We also put a
document length normalizer in the denominator of the TF formula, which causes
a penalty for long documents, since the larger the denominator is, the smaller the
TF weight is. The document length normalization is controlled by the parameter b.
The next formula is called Okapi BM25, or just BM25. It’s similar to the pivoted
length normalization formula in that it has an IDF component and a query TF
component. In the middle, the normalization is a little bit different; we have a
sublinear transformation with an upper bound. There is a length normalization
factor here as well. It achieves a similar effect as discussed before, since we put
the normalizer in the denominator. Thus, again, if a document is longer, the term
weight will be smaller.
We have now reached one of the best-known retrieval functions by thinking
logically about how to represent a document and by slowly tweaking formulas and
considering our initial assumptions.
6.3.6
Further Improvement of Basic VS Models
So far, we have talked mainly about how to place the document vector in vector
space. This has played an important role in determining the performance of the
ranking function. However, there are also other considerations that we did not
really examine in detail. We’ve assumed that we can represent a document as a
bag of words. Obviously, we can see there are many other choices. For example,
