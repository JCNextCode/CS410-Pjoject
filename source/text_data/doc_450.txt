430
Chapter 19
Joint Analysis of Text and Structured Data
Note that such an idea of regularizing likelihood function is quite general; in-
deed, the probabilistic model can be any generative model for text (such as a lan-
guage model), and the network can be also any network or graph that connects the
text objects that we hope to analyze. The regularizer can also be any regularizer that
we would like to use to capture different heuristics suitable for a particular appli-
cation; it may even be a combination of multiple regularizers. Finally, the function
f can also vary, allowing for many different ways to combine the likelihood func-
tion with the regularizers. Another variation is to specify separate constraints that
must be satisfied based on network context, making a constrained optimization
problem.
Although the idea is quite general, in practice, the challenge often lies in how
to instantiate such a general idea with specific regularizers so as to make the op-
timization problem remain tractable. Below we introduce a specific instantiation
called NetPLSA (shown in Figure 19.11), which is an extension of PLSA to incor-
porate network context by implementing the heuristic that the neighbors on the
network must have similar topic distributions.
As shown in Figure 19.11, the new modified objective function is a weighted sum
of the standard PLSA likelihood function and a regularizer where the parameter
λ ∈ [0, 1] controls the weight on the regularizer. Clearly, if λ = 0, the model reduces
to the standard PLSA. In the regularizer, we see that the main constraint is the
Network-induced prior: Neighbors have similar topic distribution
Modiﬁed objective function
PLSA log-likelihood
Quantify the difference in the
topic coverage at nodes u and v
Text collection
Network graph
Inﬂuence of
network constraint
Weight of
edge (u, v)
O(C, G) = (1 – λ) ·  (
c(w, d) log
p(θj|d)p(w|θj))
∑
d ∑
w
k
∑
j=1
+  λ  · (–1–2
w(u, v)
(p(θj|u) – p(θj|v))2)
∑
hu,vi2E
k
∑
j=1
Figure 19.11
The NetPLSA model.
