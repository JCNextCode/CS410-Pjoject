18.2 Ordinal Regression
397
p(Y = 1 | X) =
exp
�
β0 + �M
i=1 xiβi
�
1 + exp
�
β0 + �M
i=1 xiβi
�.
(18.2)
ThereareM featuresalltogetherandeachfeaturevaluexi isarealnumber.Asusual,
these features can be a representation of a text document. X is a binary response
variable0or1, where1meansX ispositiveand0meansX isnegative.Ofcourse, this
is then a standard two category categorization problem and we can apply logistic
regression. You may recall from Chapter 10 that in logistic regression, we assume
the log probability that Y = 1 is a linear function of the features. This would allow
us to also write p(Y = 1 | X) as a transformed form of the linear function of the
features. The βi’s are parameters. This is a direct application of logistic regression
for binary categorization.
If we have multiple categories or multiple levels, we will adapt the binary logistic
regression problem to solve this multilevel rating prediction, as illustrated in Fig-
ure 18.5. The idea is that we can introduce multiple binary classifiers; in each case
we ask the classifier to predict whether the rating is j or above. So, when Yj = 1, it
means the rating is j or above. When it’s 0, that means the rating is lower than j.
If we want to predict a rating in the range of 1 to k, we first have one classifier to
distinguish k versus the others. Then, we’re going to have another classifier to dis-
tinguish k − 1 from the rest. In the end, we need a classifier to distinguish between
2 and 1 which altogether gives us k − 1 classifiers.
Classiﬁer 1
p(r ≥ j|X) = eαj+∑M
i=1xiβji
—
eαj+∑M
i=1xiβji + 1
log 
= log 
= αj + ∑M
i=1xiβji  βji 2 < 
p(Yj = 1|X)
—
p(Yj = 0|X)
p(r ≥ j|X)
—
1 – p(r ≥ j|X)
Rating
Classiﬁer 2
Classiﬁer k – 1
k – 1
k – 2
…
2
1
k
Yj = 1
0
rating is j or above
rating is lower than j
Predictors: X = (x1, x2, …, xM), xi 2 <
Rating: r 2 {1, 2, …, k}
Figure 18.5
Logistic regression for multiple-level sentiment analysis.
