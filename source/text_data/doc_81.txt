4.4 Tokenization with META
61
libsvm_corpus. If only being used for classification, META can also take
LIBSVM-formatted input to create a forward_index. There are many ma-
chine learning datasets available in this format on the LIBSVM site.2
For more information on corpus storage and configuration settings, we suggest
the reader consult https://meta-toolkit.org/overview-tutorial.html.
4.4
Tokenization with META
The first step in creating an index over any sort of text data is the “tokenization”
process. At a high level, this simply means converting individual text documents
into sparse vectors of counts of terms—these sparse vectors are then typically
consumed by an indexer to output an inverted_index over your corpus.
META structures this text analysis process into several layers in order to give the
user as much power and control over the way the text is analyzed as possible.
An analyzer, in most cases, will take a “filter chain” that is used to generate the
final tokens for its tokenization process: the filter chains are always defined as a
specific tokenizer class followed by a sequence of zero or more filter classes, each
of which reads from the previous class’s output. For example, here is a simple filter
chain that lowercases all tokens and only keeps tokens with a certain length range:
icu_tokenizer → lowercase_filter → length_filter
Tokenizers always come first. They define how to split a document’s string
content into tokens. Some examples are as follows.
icu_tokenizer. converts documents into streams of tokens by following the
Unicode standards for sentence and word segmentation.
character_tokenizer. convertsdocumentsintostreamsofsinglecharacters.
Filters come next, and can be chained together. They define ways that text can
be modified or transformed. Here are some examples of filters.
length_filter. this filter accepts tokens that are within a certain length and
rejects those that are not.
icu_filter.
applies an ICU (International Components for Unicode)3 translit-
eration to each token in the sequence. For example, an accented character like
¨ı is instead written as i.
2. http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets
3. http://site.icu-project.org/; note that different versions of ICU will tokenize text in slightly
different ways!
