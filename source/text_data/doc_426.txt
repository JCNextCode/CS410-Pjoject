406
Chapter 18
Opinion Mining and Sentiment Analysis
Value
Rooms
Location
Cleanliness
resort 22.80
view 28.05
restaurant 24.47
clean 55.35
value 19.64
comfortable 23.15
walk 18.89
smell 14.38
excellent 19.54
modern 15.82
bus 14.32
linen 14.25
worth 19.20
quiet 15.37
beach 14.11
maintain 13.51
bad −24.09
carpet −9.88
wall −11.70
smelly −0.53
money −11.02
smell −8.83
bad −5.40
urine −0.43
terrible −10.01
dirty −7.85
road −2.90
filthy −0.42
overprice −9.06
stain −5.85
website −1.67
dingy −0.38
Figure 18.13
Sentiment lexicon learned by LARA. (Based on results from Wang et al. [2010])
In Figure 18.13, we show some highly weighted words and the negatively
weighted words for each of the four aspect dimensions: value, room, location, and
cleanliness. Thus, we can also learn sentiment information directly from the data.
This kind of lexicon is very useful because in general, a word like long may have
different sentiment polarities for different contexts. If we see “The battery life of
this laptop is long,” then that’s positive. But if we see “The rebooting time for the
laptop is long,” then that’s clearly not good. Even for reviews about the same prod-
uct (i.e., a laptop) the word long is ambiguous. However, with this kind of lexicon,
we can learn whether a word is positive or negative for a particular aspect. Such
a lexicon can be directly used to tag other reviews about hotels or tag comments
about hotels in social media.
Since this is almost completely unsupervised aside from the overall ratings, this
can allow us to learn from a potentially larger amount of data on the internet to
create a topic-specific sentiment lexicon. Recall that the model can infer whether
a reviewer cares more about service or the price. How do we know whether the
inferred weights are correct? This poses a very difficult challenge for evaluation.
Figure 18.14 shows prices of hotels in different cities. These are the prices of
hotels that are favored by different groups of reviewers. Here we show the ratio of
importance of value to other aspects. For example, we have value vs. location. In the
figure, “top ten” refers to the reviewers that have the highest ratios by a particular
measure. This means these top ten reviewers tend to put a lot of weight on value
as compared with other dimensions. The bottom ten refers to reviewers that have
put higher weights on other aspects than value; these are people who care about
