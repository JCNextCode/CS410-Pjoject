A.4 The Dirichlet Distribution
461
The categorical distribution is to the multinomial distribution as the Bernoulli
is to the binomial. The multinomial is the probability of observing each word ki
occur xi times in a total of n trials. If we’re given a document vector of counts, we
can use the multinomial to find the probability of observing documents with those
counts of words (regardless of position). The probability density function is given
as follows:
p(X1 = xi, . . . , Xk = xk) =
n!
x1! . . . xk!px1
1 . . . pxk
k ,
(A.11)
where
k
�
i=1
xi = n,
k
�
i=1
pi = 1.
We can also write its pdf as
p(X1 = xi, . . . , Xk = xk) =
�
��k
i=1 xi + 1
�
�k
i=1 �(xi + 1)
k�
i=1
pxi
i .
(A.12)
It should be straightforward to relate the more general multinomial distribution
to its binomial counterpart.
A.4
The Dirichlet Distribution
We now have the likelihood function determined for a distribution with k out-
comes. The conjugate prior to the multinomial is the Dirichlet. That is, if we use a
Dirichlet prior, the posterior will also be a Dirichlet.
Like the multinomial, the Dirichlet is a distribution over positive vectors that
sum to one. (The “simplex” is the name of the space where these vectors live.) Like
the Beta distribution, the parameters of the Dirichlet are reals. Here’s the pdf:
p(θ | ⃗α) =
�
��k
i=1 αi
�
�k
i=1 �(αi)
k�
i=1
θαi−1
i
.
(A.13)
In this notation we have p(θ | ⃗α). θ is what we draw from the Dirichlet; in
the Beta, it was the parameter to be used in the binomial. Here, it is the vector
of parameters to be used in the multinomial. In this sense, the Dirichlet is a
distribution that produces distributions (so is the Beta!). The hyperparameters
of the Dirichlet are also a vector (denoted with an arrow for emphasis). Instead
of just two hyperparameters as in the Beta, the Dirichlet needs k—one for each
multinomial probability.
