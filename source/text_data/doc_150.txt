130
Chapter 6
Retrieval Models
6.10. In Okapi BM25, how can we remove document length normalization by
setting a parameter? What value should it have?
6.11. Examine the Okapi BM25 retrieval function in META. You should see that
it is slightly different than the formula discussed in this chapter. What are the
differences and what do you suppose their effect is?
6.12. How are query likelihood and language models related?
6.13. In a unigram document LM, how many parameters are needed? (That is, how
many probabilities must be known in order to describe the LM?)
6.14. In a bigram document LM, how many parameters are needed?
6.15. Given a unigram language model θ estimated from this book’s content, and
two documents d1 =“information retrieval” and d2 =“retrieval information”, then
p(d1 | θ) > p(d2 | θ). True or false? Why?
6.16. For this and the next question, refer to this probabilistic retrieval method
called absolute discounting:
ps(w | d) = max(c(w, d) − δ, 0)
|d|
+ δ|d|u
|d|
. p(w | C)
and
αd = δ|d|u
|d| ,
where δ ∈ [0, 1] or |d|u is the total number of unique terms in a particular docu-
ment d.
What happens in the extreme cases where δ = 0 and δ = 1?
6.17. Does absolute discounting capture document length normalization? How?
6.18. Give two reasons why Dirichlet Prior smoothing is better than Add-1 smooth-
ing, which is defined as
ps(w | d) = c(w, d) + 1
|d| + |V | .
6.19. Which heuristics from the vector space models are captured in the general
smoothed query likelihood formula?
6.20. Is the following formula an acceptable scoring function? Why or why not?
score(q, d) =
�
w∈q,d
k . c(w, C)
c(w, d)
. ln
�N + 1
df(w)
�
.
n
navg
,
