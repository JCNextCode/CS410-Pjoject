410
Chapter 18
Opinion Mining and Sentiment Analysis
useful for determining whether a sentence (e.g.) is positive or negative. Based on the
useful features, we can either adjust the algorithm or try to fine-tune the feature set.
From a topic analysis viewpoint, we would like to ensure that the topics are
coherent and have a believable coverage and distribution over the documents in
the dataset. We mentioned that corpus log likelihood is a way to test how well
the model fits to the data. While this evaluation metric doesn’t always agree with
human judges [Chang et al. 2009], it does serve as a sanity check or proxy for true
usefulness.
Additionally, we can test the effectiveness of adding opinion mining and senti-
ment analysis to an existing system by the method discussed in Chapter 13. That
is, we can compare the system’s performance before sentiment analysis, and then
compare its performance afterwards. If the system performs statistically signifi-
cantly better under some evaluation metric relevant to the task at hand, then the
sentiment analysis is a definitive improvement.
Bibliographic Notes and Further Reading
Opinion mining and sentiment analysis have been extensively studied. Two ex-
cellent books on this general topic are the book Opinion Mining and Sentiment
Analysis [Pang and Lee 2008] and the book Sentiment Analysis and Opinion Min-
ing [Liu 2012]. Multiple extensions of topic models for analyzing opinionated topics
have been made (e.g., topic-sentiment mixture model [Mei et al. 2007a], multi-grain
topic model [Titov and McDonald 2008], and aspect and sentiment unification
model [Jo and Oh 2011]). Techniques for Latent Aspect Rating Analysis are mainly
covered in two KDD papers [Wang et al. 2010], [Wang et al. 2011].
Exercises
18.1. In this chapter, we mainly discussed how to determine overall sentiment for
a text object. Imagine that we already have the sentiment information as part of
the object and we are instead interested in identifying the target of the sentiment.
Brainstorm some ideas using NLP techniques mentioned in this book.
18.2. META has an implementation of the LDA topic modeling algorithm, which
contains symmetric priors for the word and topic distributions. Modify META to
contain non-uniform priors on the topic-word distributions to encode some addi-
tional knowledge into the prior. For example, in the sentiment analysis task, create
two prior distributions that have high weights on particular “good” and “bad” topic
distributions. That is, the prior for the “good” topic should probably weight the
